# Embodied Intelligence Stack (EIS)
A three‑stage exploration of:
- Learning (Reinforcement Learning)
- Perception(e.g., SLAM, LiDAR),
- Inference (Active Inference) in embodied agents.

Resources:
- [Navigation and Exploration with Active Inference: from Biology to Industry](https://arxiv.org/html/2508.07269v1?fbclid=IwY2xjawP6AUhleHRuA2FlbQIxMABicmlkETFNOGxIaTBaeDd3YnpOUGxoc3J0YwZhcHBfaWQQMjIyMDM5MTc4ODIwMDg5MgABHvHINRC9ipY5RZqwpquLal4Eud44Iep6FHAV9JU-MXUGpK0LThSmQzPETSk__aem_h7zSmhJf7W42DCM0fiw6hQ)
- [Tutorial 1: Active inference from scratch](https://pmc.ncbi.nlm.nih.gov/articles/PMC8956124/?fbclid=IwY2xjawP6AVBleHRuA2FlbQIxMABicmlkETFNOGxIaTBaeDd3YnpOUGxoc3J0YwZhcHBfaWQQMjIyMDM5MTc4ODIwMDg5MgABHhVw1dQ4RfO07kVS3hvhb1i7pDPiDoZidgN6JI0AWeV_we2I5T-sbnvtP_Py_aem_mpdLPnhOxxvTDwc4TL_L8g)
- [A step-by-step tutorial on active inference and its application to empirical data](https://pmc.ncbi.nlm.nih.gov/articles/PMC8956124/?fbclid=IwY2xjawP6AVBleHRuA2FlbQIxMABicmlkETFNOGxIaTBaeDd3YnpOUGxoc3J0YwZhcHBfaWQQMjIyMDM5MTc4ODIwMDg5MgABHhVw1dQ4RfO07kVS3hvhb1i7pDPiDoZidgN6JI0AWeV_we2I5T-sbnvtP_Py_aem_mpdLPnhOxxvTDwc4TL_L8g)
- [How Active Inference Could Help Revolutionise Robotics](https://pmc.ncbi.nlm.nih.gov/articles/PMC8946999/?fbclid=IwY2xjawP6AVlleHRuA2FlbQIxMABicmlkETFNOGxIaTBaeDd3YnpOUGxoc3J0YwZhcHBfaWQQMjIyMDM5MTc4ODIwMDg5MgABHrI66yEYqqQVQA9Fpcplq-Cm0LdHMRiDaC9fQWVG-9iPaagEPvDYZXxrnosQ_aem_Lp_GSXNn2YhpVA8OSU-BiQ)


## Project Overview

Embodied Intelligence Stack (EIS) is a three‑level exploration of how intelligent agents learn, perceive, and infer from first principles. 
- The project begins with foundational reinforcement learning, building core concepts and algorithms from scratch. 
- Level 2 extends these foundations into robotics, SLAM, and perception, integrating deep RL to enable agents that act in complex, embodied environments. 
- Level 3 culminates in a first‑principles implementation of Bayesian Active Inference, unifying learning, action, and belief‑updating into a coherent cognitive architecture.

EIS is designed as a modular, reproducible research framework that bridges theory, engineering, and embodied intelligence.

## Vision

**EIS reflects my long‑term research vision to build intelligence from first principles** through mechanisms that are mathematically grounded, transparent, and embodied.
I am interested in agents whose behavior emerges from the integration of learning, perception, and probabilistic reasoning, not from black‑box optimization alone.

**By progressing from foundational RL to robotics and Bayesian Active Inference, EIS expresses a unified view of intelligent behavior:** agents should learn from experience, act in the world, and update their beliefs in a principled way.
This project is both a technical framework and a statement of research identity aimed at graduate‑level study, robotics labs, and industry teams working on embodied or neuromorphic AI.

---

## Project Structure

### Level 1: First‑Principles Reinforcement Learning
Builds the mathematical and algorithmic foundations of RL from scratch.

**Focus areas include:**
- Value‑based and policy‑based methods
- Exploration strategies
- Tabular and function‑approximation settings
- Simple agent‑environment loops
- Clear, transparent implementations

This level establishes the core learning mechanisms that later stages build upon.

---

### Level 2: Robotics, SLAM, and Perception (Deep RL)
Extends Level 1 into embodied settings.

**Focus areas include:**
- Robot kinematics and control
- SLAM fundamentals
- Visual and sensor‑based perception
- Deep RL for continuous control
- Integration of learning with real‑world constraints

This level connects abstract RL principles to physical agents and perceptual pipelines.

---

### Level 3: Bayesian Active Inference (First Principles)
A principled exploration of inference‑driven behavior.

**Focus areas include:**
- Generative models and variational inference
- Perception‑action loops
- Free‑energy minimization
- Planning as inference
- Integration with robotics and perception

This level unifies learning, belief‑updating, and action selection into a single cognitive architecture.

---

## Status

- **Level 1:** In progress
- **Level 2:** Planned
- **Level 3:** Scheduled for delivery by March 15

